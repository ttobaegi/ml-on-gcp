{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Debugging.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttobaegi/ml-on-gcp/blob/main/ML_Debugging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IPfZryiJJXv"
      },
      "source": [
        "# ML Debugging practice : Debugging a Simple Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vC0sXBEEgUF"
      },
      "source": [
        "- Why ML debugging is harder than traditional debugging \n",
        "- *debugging a simple regression problem with one feature and one label*.\n",
        "\n",
        "\n",
        "> 1. Create the dataset.\n",
        "> 2. Try to fit the data with a simple model.\n",
        "> 3. Debug the model.\n",
        "> 4. Demonstrate exploding gradients.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-vpfBAN48gW"
      },
      "source": [
        "## Create the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYj-8T48e6Rw"
      },
      "source": [
        "# Reset environment for a new run\n",
        "% reset -f\n",
        "\n",
        "# Load Libraries\n",
        "from os.path import join # for joining file pathnames\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set Pandas display options\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aN24LlKj7LM"
      },
      "source": [
        "# Create the data :  1 feature with values 0 to 9  &  labels : the same data with some noise added\n",
        "# To match the convention (rows are examples and columns are features), transpose data. \n",
        "# Before transposing vectors, MUST convert them to matrices.\n",
        "\n",
        "features = np.array(range(10))\n",
        "features = features[:, np.newaxis]\n",
        "# Create labels by adding noise distributed around 0\n",
        "labels = features + np.random.random(size=[10,1]) - 0.5"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6fomFA9pnrF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e6569b87-b559-417b-ab08-aaa8d140de7c"
      },
      "source": [
        "# Verify that the data roughly lies in a straight line and, therefore, is easily predicted\n",
        "# Visualize the data\n",
        "plt.scatter(features,labels)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7faf7da50ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAVm0L6GCwrs"
      },
      "source": [
        "## Fit Simple Data with Simple Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgn_hESwkhmd"
      },
      "source": [
        "`Keras API` to train models quickly in a few lines of code using high-level APIs. \n",
        "- typical nn : `sequential` model with fully-connected, or `dense`, layers.\n",
        "\n",
        "- simple dataset ⇒ neural network with just 1 neuron \n",
        "- Define a neural network with 1 layer having 1 neuron using the model type `keras.Sequential` with the layer type `keras.layers.Dense`.\n",
        "- model with 1 layer and 2 parameters (weight and bias) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2SHLw83z4fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020a9ba2-5178-41b2-d8db-01486ab8e33f"
      },
      "source": [
        "# Delete any existing assignment to \"model\"\n",
        "model = None\n",
        "\n",
        "# Use a sequential model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Add a layer with 1 neuron. Use the popular \"tanh\" activation function\n",
        "model.add(keras.layers.Dense(units=1,             # 1 neuron\n",
        "                             activation='tanh',   # 'tanh'\n",
        "                             input_dim=1))         # number of feature cols=1\n",
        "\n",
        "# Model calculates loss using mean-square error (MSE)\n",
        "# Model trains using Adam optimizer with learning rate = 0.001\n",
        "model.compile(optimizer=tf.optimizers.Adam(0.001),\n",
        "              loss='mse',\n",
        "             )\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERliMzkpvm8n"
      },
      "source": [
        "Now, train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldasx-XNvr53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10182998-61b7-4530-f908-2efd75368ce4"
      },
      "source": [
        "model.fit(x=features,\n",
        "          y=labels,\n",
        "          epochs=10,    # train for 10 epochs\n",
        "          batch_size=10,# use 10 examples per batch\n",
        "          verbose=1)    # verbose=1 prints progress per epoch"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 21.6479\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 21.6478\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 21.6477\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 21.6476\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.6475\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 21.6474\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 21.6473\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 21.6472\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.6471\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 21.6470\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf793db650>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMcdO6GPnBCK"
      },
      "source": [
        "**loss stubbornly refuses to decrease.** \n",
        "\n",
        "### To debug your model\n",
        "\n",
        "\n",
        "* **Transforming data**: You data is not transformed. You can experiment by transforming the data appropriately and retraining the model.\n",
        "* **Activation function**: The `tanh` activation function cannot predict values >1. Besides, in a regression problem, the last layer should always use the linear activation function. Therefore, should you use  `activation='linear'`?\n",
        "* **Hyperparameter values**: Should you adjust any hyperparameter values to try reducing loss?\n",
        "* **Simpler model**: The model development process recommends starting with a simple model. A linear model is simpler than your nonlinear model. Should you use `activation='linear'`?\n",
        "* **Change optimizer**: The model uses the Adam optimizer. You can fall back to the gradient descent optimizer by using `optimizer=keras.optimizers.SGD()`.\n",
        "\n",
        "\n",
        "*Reference : [model development process](https://developers.google.com/machine-learning/testing-debugging/common/overview)*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej14ORiDUIM3"
      },
      "source": [
        "## Solution: Getting Loss to Decrease"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfGdTkrdUJcm"
      },
      "source": [
        "Before trying to adjust specific model parameters, such as the hyperparameter values, **first, check for good development practices**,\n",
        "\n",
        "####  two best practices for linear model\n",
        "1. Regression: In a regression problem, the last layer must always be linear.\n",
        "2. Start simple: Since a linear model is simpler than a nonliner model, start with a linear model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fKzl07oWjcD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "74661797-930a-437b-96f5-66ec44b821ce"
      },
      "source": [
        "model = None\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(1, activation='linear', input_dim=1))\n",
        "model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse')\n",
        "trainHistory = model.fit(features, labels, epochs=10, batch_size=1, verbose=1)\n",
        "# Plot loss curve\n",
        "plt.plot(trainHistory.history['loss'])\n",
        "plt.title('Loss Curves')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6921\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 1.5673\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4707\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3754\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2782\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1716\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1033\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0200\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9388\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8721\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss Curves')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkcKovAAk4r_"
      },
      "source": [
        "loss decreases, albeit slowly! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXckvj-FlEzl"
      },
      "source": [
        "## Solution: Reaching Convergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgBZXOuClIeX"
      },
      "source": [
        "Q. How can you get your loss to converge? \n",
        "\n",
        "> Your loss isn't decreasing fast enough. From the guidance on [Learning Rate](https://developers.google.com/machine-learning/crash-course/reducing-loss/learning-rate), **you can increase the learning rate to train faster**.\n",
        "\n",
        "- to increase the learning rate to 0.1 ⇒ the model reaches convergence quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRkbxeLVlZoy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dea877f-ea1f-44fa-9646-cf140164a75a"
      },
      "source": [
        "model = None\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(1, activation='linear', input_dim=1))\n",
        "model.compile(optimizer=tf.optimizers.Adam(0.1), loss='mse')  # to increase the learning rate to 0.1\n",
        "model.fit(features, labels, epochs=5, batch_size=1, verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 130.4615\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 0s 1ms/step - loss: 49.9405\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 13.4702\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.3852\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf792966d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7AQ9pWp6E7J"
      },
      "source": [
        "quickly get a very low loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Mk-ivUgf9o"
      },
      "source": [
        "\n",
        "1. confirm the model works by predicting results for values [0,9] \n",
        "2. superimposing them on top of the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRgXYbBst0Pd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "4f8f8e4a-decd-4b9c-e9b5-eebcb32ba496"
      },
      "source": [
        "# get predictions\n",
        "featuresPred = model.predict(features, verbose=1)\n",
        "# Plot original features and predicted values\n",
        "featuresPred = np.transpose(featuresPred)\n",
        "plt.scatter(range(10), labels, c=\"blue\")\n",
        "plt.scatter(range(10), featuresPred, c=\"red\")\n",
        "plt.legend([\"Original\", \"Predicted\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7faf77b7af90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s8gb4rTTei7"
      },
      "source": [
        "the predictions match the features very well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38cbAf2RpHtI"
      },
      "source": [
        "## Summary of Case Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjNDlFMMMsTc"
      },
      "source": [
        "When debugging ML models \n",
        "\n",
        "- first attempt to diagnose the problem and apply the appropriate fix\n",
        "  1. For example, if you had changed your optimizer using `optimizer='sgd'`, then your model also converges faster. \n",
        "  2. However, the problem was not with the optimizer but with the learning rate. **Changing the optimizer only helps because `optimizer='sgd'` has a higher default learning rate than `optimizer='adam'`**.\n",
        "\n",
        "In real-world ML, models take long to train. You should keep your training cycles as short as possible. Therefore, **increasing the learning rate is the correct fix**.\n",
        "\n",
        "- how debugging in ML is n-dimensional, and therefore you must use your understanding of model mechanics to narrow down your options. \n",
        "Because running experiments in ML is time consuming, requires careful setup, and can be subject to reproducibility issues, it's important to use your understanding of model mechanics to  narrow down options without having to experiment.\n",
        "\n",
        "Lastly, according to development best practices, you should transform your feature data appropriately. This Colab did not transform the feature data because transformation is not required for convergence. However, you should always transform data appropriately. Here, you could normalize your feature data using z-score or scale the feature data to [0,1]. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEGEERnbglN9"
      },
      "source": [
        "# Exploding Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s92MiwHIgm58"
      },
      "source": [
        "A common problem in model training is a loss that \"explodes\" or becomes `nan`. A common cause is anomalous feature data, such as outliers and `nan` values, or a high learning rate. The following sections demonstrate these causes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOg62A4KiLk3"
      },
      "source": [
        "## Cause: High Learning Rate\n",
        "\n",
        "Create data in the range [0,50] and show that the gradient explodes when you train the model **using a learning rate of 0.01**. Then you'll reduce the learning rate to make the model converge.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "826oEnhXOi2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "39e75840-fe9d-44e3-ae29-09225732ae80"
      },
      "source": [
        "# create data with large values\n",
        "features = np.array(range(50))\n",
        "# generate labels\n",
        "labels = features + np.random.random(features.shape) - 0.5\n",
        "\n",
        "# Transpose data for input\n",
        "[features, labels] = [features.transpose(), labels.transpose()]\n",
        "\n",
        "plt.scatter(range(len(features)), features)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7faf79146410>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckm1y8fCZ1s0"
      },
      "source": [
        "Run the following cell to train a model with a learning rate of 0.01. You will get `inf` for your loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE8LTD1CZy98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ef5223-5bbc-4164-fc58-55e774dd6628"
      },
      "source": [
        "# Train on raw data\n",
        "model = None\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(1, input_dim=1, activation='linear'))\n",
        "model.compile(optimizer=keras.optimizers.SGD(0.01), loss='mse')\n",
        "model.fit(features, labels, epochs=5, batch_size=10, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1975263035392.0000\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 1122488772398462529437696.0000\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 582886582991681130328971235890823168.0000\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: inf\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf7906d2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9QgTarmdWxu"
      },
      "source": [
        "To demonstrate that the high learning rate makes the loss explore, reduce the learning rate to `0.001`. Your loss will converge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_Sv-12X895B",
        "outputId": "65666a60-18f3-4be9-838a-1ab83b425f6e"
      },
      "source": [
        "# Train on raw data\n",
        "model = None\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(1, input_dim=1, activation='linear'))\n",
        "model.compile(optimizer=keras.optimizers.SGD(0.001), loss='mse')\n",
        "model.fit(features, labels, epochs=5, batch_size=10, verbose=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 330.8571\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 2.1447\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0965\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1099\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0920\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf79065590>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWRyRZaXt_l9"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NmLFsc8Gz67"
      },
      "source": [
        "* The n-dimensional nature of debugging in ML makes ML debugging hard.\n",
        "* For effective debugging, understanding model mechanics is important.\n",
        "* Start with a simple model.\n",
        "* Exploding gradients incorrect normalization in the model, mis-configuration of FeatureColumns, etc., than raw data containing NaNs."
      ]
    }
  ]
}